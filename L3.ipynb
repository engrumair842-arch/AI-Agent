{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ce8079-c3b4-4537-844e-7e6d6706e923",
   "metadata": {},
   "source": [
    "# Lab 1: Building your Agent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c9a24-4d77-43ca-84fd-5155b4e4c777",
   "metadata": {},
   "source": [
    "The agent is comprised of a router using OpenAI function calling, and a set of three tools: a database lookup tool, a data analysis tool, and a code generator to create graphs.\n",
    "\n",
    "<img src=\"images/agent.png\" width=\"500\"/>\n",
    "\n",
    "\n",
    "The agent can lookup information from a local file, perform analysis on that information, and graph results. The example local file is a log of transactions at a local store. The agent can help the store owners understand trends and anomalies in their sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a4f62-de25-4a66-8cdb-f33d1e92ad92",
   "metadata": {},
   "source": [
    "## Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4d6c602-28a5-42f2-9e53-33dac5846cba",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import duckdb\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from helper import get_openai_api_key\n",
    "from helper import get_groq_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd227e-0d4f-4f64-922c-cc4606a10090",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> ðŸ’» &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf15696-0cfa-464a-b698-b5877cbbd6b3",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Your results might differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7f1fb-fea2-475b-9a90-a70eea108153",
   "metadata": {},
   "source": [
    "## Initializing the OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5bbb872-2328-4283-b544-9a4c6ba960d3",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# initialize the Groq client\n",
    "# groq_api_key = get_groq_api_key()\n",
    "client = OpenAI(api_key=get_openai_api_key)\n",
    "# from groq import Groq\n",
    "\n",
    "# client = Groq(api_key=groq_api_key)\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "# MODEL = \"openai/gpt-oss-120b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503d9fe-e023-4446-b1b2-4633ab0efd8e",
   "metadata": {},
   "source": [
    "## Defining the tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f909b1-689e-4d61-8f8d-c6f35520ad66",
   "metadata": {},
   "source": [
    "Let's start by creating the three tools the agent will be able to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded04f0-ea0d-48b1-83d0-1bfc84ea170e",
   "metadata": {},
   "source": [
    "### Tool 1: Database Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761c2e1-b100-4d3c-b4d7-8c3b4b709c54",
   "metadata": {},
   "source": [
    "This first tool reads from a local parquet file that contains the transaction data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78dbdaf9-d5e0-4f0d-aa41-318020ab7b1e",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "# define the path to the transactional data\n",
    "# TRANSACTION_DATA_FILE_PATH = 'data/Store_Sales_Price_Elasticity_Promotions_Data.parquet'\n",
    "DATASET_FILE_PATH = 'data/Titanic-Dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a0d24-185a-47a4-a27b-3959cb1e0ba1",
   "metadata": {},
   "source": [
    "This database lookup tool works using three steps. \n",
    "\n",
    "<img src=\"images/tool1.png\" width=\"500\"/>\n",
    "\n",
    "1. First, it creates the SQL table from a local file, if not already done.\n",
    "2. Second, it translates the original prompt into an sql query (using an LLM call).\n",
    "3. Finally, it runs that query against the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dd37619-7785-41de-9986-6260d6e17221",
   "metadata": {
    "height": 164
   },
   "outputs": [],
   "source": [
    "# prompt template for step 2 of tool 1\n",
    "SQL_GENERATION_PROMPT = \"\"\"\n",
    "Generate an SQL query based on a prompt. Do not reply with anything besides the SQL query.\n",
    "The prompt is: {prompt}\n",
    "\n",
    "The available columns are: {columns}\n",
    "The table name is: {table_name}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b7c2f28-2ec1-43de-b555-d300d916c47d",
   "metadata": {
    "height": 249
   },
   "outputs": [],
   "source": [
    "# code for step 2 of tool 1\n",
    "def generate_sql_query(prompt: str, columns: list, table_name: str) -> str:\n",
    "    \"\"\"Generate an SQL query based on a prompt\"\"\"\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(prompt=prompt, \n",
    "                                                    columns=columns, \n",
    "                                                    table_name=table_name)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cdb59fa5-f096-4ba6-9967-4dffea8aa5cb",
   "metadata": {
    "height": 436
   },
   "outputs": [],
   "source": [
    "# code for tool 1\n",
    "def lookup_given_dataset(prompt: str) -> str:\n",
    "    \"\"\"Implementation of given dataset csv file using SQL\"\"\"\n",
    "    try:\n",
    "\n",
    "        # define the table name\n",
    "        table_name = \"dataset\"\n",
    "        \n",
    "        # step 1: read the parquet file into a DuckDB table\n",
    "        # df = pd.read_parquet(TRANSACTION_DATA_FILE_PATH)\n",
    "        df = pd.read_csv(DATASET_FILE_PATH)\n",
    "        duckdb.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM df\")\n",
    "\n",
    "        # step 2: generate the SQL code\n",
    "        sql_query = generate_sql_query(prompt, df.columns, table_name)\n",
    "        # clean the response to make sure it only includes the SQL code\n",
    "        sql_query = sql_query.strip()\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "        \n",
    "        # step 3: execute the SQL query\n",
    "        result = duckdb.sql(sql_query).df()\n",
    "        \n",
    "        return result.to_string()\n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f044f10e-6fd1-4514-94b5-3d62fe2b23d1",
   "metadata": {},
   "source": [
    "Great! Now let's test the first tool and make sure it worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7391d9ff-55f1-4b1d-bfe5-a4df403bf4b9",
   "metadata": {
    "height": 62
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PassengerId  Survived  Pclass                                                       Name     Sex    Age  SibSp  Parch           Ticket     Fare    Cabin Embarked\n",
      "0           816         0       1                                           Fry, Mr. Richard    male    NaN      0      0           112058   0.0000     B102        S\n",
      "1           861         0       3                                    Hansen, Mr. Claus Peter    male  41.00      2      0           350026  14.1083     None        S\n",
      "2           525         0       3                                          Kassem, Mr. Fared    male    NaN      0      0             2700   7.2292     None        C\n",
      "3           311         1       1                             Hays, Miss. Margaret Bechstein  female  24.00      0      0            11767  83.1583      C54        C\n",
      "4           695         0       1                                            Weir, Col. John    male  60.00      0      0           113800  26.5500     None        S\n",
      "5           464         0       2                               Milling, Mr. Jacob Christian    male  48.00      0      0           234360  13.0000     None        S\n",
      "6           133         0       3             Robins, Mrs. Alexander A (Grace Charity Laury)  female  47.00      1      0        A/5. 3337  14.5000     None        S\n",
      "7            55         0       1                             Ostby, Mr. Engelhart Cornelius    male  65.00      0      1           113509  61.9792      B30        C\n",
      "8           675         0       2                                 Watson, Mr. Ennis Hastings    male    NaN      0      0           239856   0.0000     None        S\n",
      "9           172         0       3                                       Rice, Master. Arthur    male   4.00      4      1           382652  29.1250     None        Q\n",
      "10           79         1       2                              Caldwell, Master. Alden Gates    male   0.83      0      2           248738  29.0000     None        S\n",
      "11          611         0       3  Andersson, Mrs. Anders Johan (Alfrida Konstantia Brogren)  female  39.00      1      5           347082  31.2750     None        S\n",
      "12          618         0       3            Lobb, Mrs. William Arthur (Cordelia K Stanlick)  female  26.00      1      0        A/5. 3336  16.1000     None        S\n",
      "13           88         0       3                              Slocovski, Mr. Selman Francis    male    NaN      0      0  SOTON/OQ 392086   8.0500     None        S\n",
      "14          818         0       2                                         Mallet, Mr. Albert    male  31.00      1      1  S.C./PARIS 2079  37.0042     None        C\n",
      "15          589         0       3                                      Gilinski, Mr. Eliezer    male  22.00      0      0            14973   8.0500     None        S\n",
      "16          323         1       2                                  Slayter, Miss. Hilda Mary  female  30.00      0      0           234818  12.3500     None        Q\n",
      "17          790         0       1                                   Guggenheim, Mr. Benjamin    male  46.00      0      0         PC 17593  79.2000  B82 B84        C\n",
      "18          178         0       1                                 Isham, Miss. Ann Elizabeth  female  50.00      0      0         PC 17595  28.7125      C49        C\n",
      "19          302         1       3                                         McCoy, Mr. Bernard    male    NaN      2      0           367226  23.2500     None        Q\n"
     ]
    }
   ],
   "source": [
    "example_data = lookup_given_dataset(\"just return random 20 records from the titanic dataset\")\n",
    "print(example_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481388d3-578d-492b-a53c-46811ac573d7",
   "metadata": {},
   "source": [
    "### Tool 2: Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a6d53-fcae-41bd-9d3c-e90960874737",
   "metadata": {},
   "source": [
    "The second tool can analyze the returned data and display conclusions to users.\n",
    "\n",
    "<img src=\"images/tool2.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3510f56-30c5-446d-a41f-bec5e4a1de36",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# Construct prompt based on analysis type and data subset\n",
    "DATA_ANALYSIS_PROMPT = \"\"\"\n",
    "Analyze the following data: {data}\n",
    "Your job is to answer the following question: {prompt}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23cb7932-79be-455f-b4fb-83db752d5e43",
   "metadata": {
    "height": 232
   },
   "outputs": [],
   "source": [
    "# code for tool 2\n",
    "def analyze_given_dataset(prompt: str, data: str) -> str:\n",
    "    \"\"\"Implementation of AI-powered Titanic data analysis\"\"\"\n",
    "    formatted_prompt = DATA_ANALYSIS_PROMPT.format(data=data, prompt=prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    analysis = response.choices[0].message.content\n",
    "    return analysis if analysis else \"No analysis could be generated\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97ea8e-c101-4e1b-88d0-8ce088590373",
   "metadata": {},
   "source": [
    "This tool is relatively simple, but let's still test it out to be sure things are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18042c0f-ba38-4ebd-925c-9bc7ae0f0b21",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Analyzing the provided dataset related to the survival of Titanic passengers, we can observe several trends and patterns based on various attributes. Here are some key points:\n",
       "\n",
       "1. **Survival Rates by Gender**:\n",
       "   - Among the entries, there are both male and female passengers. The survival rates appear to differ by sex, aligning with historical records that indicate women and children had a higher chance of survival during the Titanic disaster. For instance, both entries for Miss. Margaret Bechstein Hays and Miss. Hilda Mary Slayter survived, while many male passengers did not.\n",
       "\n",
       "2. **Pclass Influence**:\n",
       "   - The dataset includes passengers from different classes (1, 2, 3). Higher-class passengers (Pclass 1) seem to have a higher chance of survival. For example, the only two passengers who survived from Pclass 1 in the provided data are both female. This is supported by historical statistics showing that first-class passengers had better access to lifeboats.\n",
       "\n",
       "3. **Age Factor**:\n",
       "   - The ages of passengers vary significantly. There are both very young (e.g., Master. Arthur Rice at 4 years old) and older passengers (e.g., Col. John Weir at 60). Survival rates seem to favor younger individuals and particularly females. The youngest survivor noted is the infant Caldwell, highlighting the tendency to prioritize women's and children's safety during the evacuation.\n",
       "\n",
       "4. **Family Relations**:\n",
       "   - The \"SibSp\" (siblings/spouses) and \"Parch\" (parents/children) columns indicate family connections. Some survivors like Caldwell (Master. Alden Gates) had family members aboard, while many passengers without family onboard did not survive. This suggests that family units may have been prioritized during rescues or had opportunities to assist each other in survival.\n",
       "\n",
       "5. **Ticket Fare & Class**:\n",
       "   - There is a strong connection between the ticket fare and the passenger class. Higher fares typically correspond to higher classes. Those who paid a more considerable fare (often in Pclass 1) stand a better chance of survival, underscoring historical patterns of social class impact on survival rates.\n",
       "\n",
       "6. **Embarkation Points**:\n",
       "   - The \"Embarked\" column shows where each passenger boarded (C, Q, S). While more extensive data would be needed for a robust analysis, this may provide insights about survival patterns based on embarkation location. \n",
       "\n",
       "7. **Missing Ages**:\n",
       "   - Several records have missing age values (NaN), which could skew analysis or be indicative of incomplete data records. Understanding how missing data correlates with survival could be vital for precise insights.\n",
       "\n",
       "8. **Cabin Values**:\n",
       "   - The presence or absence of cabin data might indicate social status. Those with cabin assignments are more likely to belong to a higher class and tend to have higher survival rates. This characteristic could be analyzed further in relation to how the placement in the ship correlates with survival outcomes.\n",
       "\n",
       "Overall, these trends highlight significant correlations between sex, class, age, family relations, and the likelihood of survival in the Titanic disaster. A deeper statistical analysis and larger dataset would allow for more robust conclusions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(analyze_given_dataset(prompt=\"what trends do you see in this data\", \n",
    "                         data=example_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b071118-7538-4e21-a709-f50dcc606260",
   "metadata": {},
   "source": [
    "### Tool 3: Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b694537-bafd-4df3-8354-0b6083d3d7ea",
   "metadata": {},
   "source": [
    "The third tool generates python code to create the requested graphs from the returned data of the first tool. It consists of two steps:\n",
    "<img src=\"images/tool3.png\" width=\"500\"/>\n",
    "1. First, it creates the chart configuration: chart type, title, data, lables for x-axis and y-axis (using an LLM call).\n",
    "2. Second, it generates the python code based on the chart configuration of the first step (using an LLM call)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5faad9a1-4452-4b89-98e6-c6a8a09f98cf",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# prompt template for step 1 of tool 3\n",
    "CHART_CONFIGURATION_PROMPT = \"\"\"\n",
    "Generate a chart configuration based on this data: {data}\n",
    "The goal is to show: {visualization_goal}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd462935-d2c5-4de1-a094-b7bdf951cd66",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# class defining the response format of step 1 of tool 3\n",
    "class VisualizationConfig(BaseModel):\n",
    "    chart_type: str = Field(..., description=\"Type of chart to generate\")\n",
    "    x_axis: str = Field(..., description=\"Name of the x-axis column\")\n",
    "    y_axis: str = Field(..., description=\"Name of the y-axis column\")\n",
    "    title: str = Field(..., description=\"Title of the chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3396ccea-1e06-42fa-a667-2d8fc8332df7",
   "metadata": {
    "height": 708
   },
   "outputs": [],
   "source": [
    "# code for step 1 of tool 3\n",
    "def extract_chart_config(data: str, visualization_goal: str) -> dict:\n",
    "    \"\"\"Generate chart visualization configuration\n",
    "    \n",
    "    Args:\n",
    "        data: String containing the data to visualize\n",
    "        visualization_goal: Description of what the visualization should show\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing user required chart configuration\n",
    "    \"\"\"\n",
    "    formatted_prompt = CHART_CONFIGURATION_PROMPT.format(data=data,\n",
    "                                                         visualization_goal=visualization_goal)\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "        response_format=VisualizationConfig,\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Extract axis and title info from response\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # Return structured chart config\n",
    "        return {\n",
    "            \"chart_type\": content.chart_type,\n",
    "            \"x_axis\": content.x_axis,\n",
    "            \"y_axis\": content.y_axis,\n",
    "            \"title\": content.title,\n",
    "            \"data\": data\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"chart_type\": \"line\", \n",
    "            \"x_axis\": \"date\",\n",
    "            \"y_axis\": \"value\",\n",
    "            \"title\": visualization_goal,\n",
    "            \"data\": data\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0473365-8fb6-4e30-962d-9599cf514323",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# prompt template for step 2 of tool 3\n",
    "CREATE_CHART_PROMPT = \"\"\"\n",
    "Write python code to create a chart based on the following configuration.\n",
    "Only return the code, no other text.\n",
    "config: {config}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0832853e-e7dd-44eb-8fec-8f4524b9baa4",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "# code for step 2 of tool 3\n",
    "def create_chart(config: dict) -> str:\n",
    "    \"\"\"Create a chart based on the configuration\"\"\"\n",
    "    formatted_prompt = CREATE_CHART_PROMPT.format(config=config)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    code = response.choices[0].message.content\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    code = code.strip()\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0e4e96e8-0ec3-4580-be1e-d239d26c609b",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# code for tool 3\n",
    "def generate_visualization(data: str, visualization_goal: str) -> str:\n",
    "    \"\"\"Generate a visualization based on the data and goal\"\"\"\n",
    "    config = extract_chart_config(data, visualization_goal)\n",
    "    code = create_chart(config)\n",
    "    try:\n",
    "        exec(code)\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing visualization code: {str(e)}\")\n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7675259b-2978-4f08-bffa-804f0a65395c",
   "metadata": {},
   "source": [
    "Great, now let's try the third tool out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "001d0743-5b02-4cfc-a6a4-5b0bba80ea30",
   "metadata": {
    "height": 79
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing visualization code: Error tokenizing data. C error: Expected 15 fields in line 3, saw 16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:29: SyntaxWarning: invalid escape sequence '\\s'\n"
     ]
    }
   ],
   "source": [
    "code = generate_visualization(example_data, \n",
    "                              \"Show a bar chart of the number of survivors by age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7653b-a90d-4447-9b6b-646b00e5164b",
   "metadata": {},
   "source": [
    "## Defining the Router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b823b2a6-1567-4a03-b829-22f6a3e167ea",
   "metadata": {},
   "source": [
    "Now that all of the tools are defined, you can create the router. The router will take the original user input, and is responsible for calling any tools. After each tool call is completed, the agent will return to router to determine whether another tool should be called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d658c1a5-6328-4ca1-bdcf-7c03328aa0c8",
   "metadata": {},
   "source": [
    "### Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf85e6a-c708-4ed5-8f43-e996c5f38c7f",
   "metadata": {},
   "source": [
    "Let's define the tools in a way that can be understood by our OpenAI model. OpenAI understands a specific JSON format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d35f5886-32d7-4bc3-968b-4485ce20d7a3",
   "metadata": {
    "height": 946
   },
   "outputs": [],
   "source": [
    "# Define tools/functions that can be called by the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_given_dataset\",\n",
    "            \"description\": \"Look up data from a given dataset\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_given_dataset\", \n",
    "            \"description\": \"Analyze given data to extract insights\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_given_dataset tool's output.\"},\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_visualization\",\n",
    "            \"description\": \"Generate Python matplotlib code to create data visualizations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\", \n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_given_dataset tool's output.\"},\n",
    "                    \"visualization_goal\": {\"type\": \"string\", \"description\": \"The goal of the visualization.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"visualization_goal\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dictionary mapping function names to their implementations\n",
    "tool_implementations = {\n",
    "    \"lookup_given_dataset\": lookup_given_dataset,\n",
    "    \"analyze_given_dataset\": analyze_given_dataset, \n",
    "    \"generate_visualization\": generate_visualization\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291cea7-d45f-429c-845a-53ba8cfc7485",
   "metadata": {},
   "source": [
    "### Router Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7edb47-99cc-45d0-8d13-5d6238aee2a2",
   "metadata": {},
   "source": [
    "The router is composed of a main loop method, and a method to handle the tool calls that you get back from the model.\n",
    "\n",
    "<img src=\"images/router.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f87aa9",
   "metadata": {},
   "source": [
    "The following two cells define the function `handle_tool_calls` and the variable `SYSTEM_PROMPT`, which will be used by the function `run_agent` defining the router logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce938658-35c9-4cda-b0d8-0b89494830c4",
   "metadata": {
    "height": 198
   },
   "outputs": [],
   "source": [
    "# code for executing the tools returned in the model's response\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    \n",
    "    for tool_call in tool_calls:   \n",
    "        function = tool_implementations[tool_call.function.name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        result = function(**function_args)\n",
    "        messages.append({\"role\": \"tool\", \"content\": result, \"tool_call_id\": tool_call.id})\n",
    "        \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b24bce5-477f-4e21-af18-4b784282aaa1",
   "metadata": {
    "height": 79
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that can answer questions about the user given dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0eacdb0-d8c4-4686-9fda-7b7c12ae2c35",
   "metadata": {
    "height": 555
   },
   "outputs": [],
   "source": [
    "def run_agent(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "        \n",
    "    # Check and add system prompt if needed\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
    "            messages.append(system_prompt)\n",
    "\n",
    "    while True:\n",
    "        print(\"Making router call to OpenAI\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "        )\n",
    "        messages.append(response.choices[0].message)\n",
    "        tool_calls = response.choices[0].message.tool_calls\n",
    "        print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "\n",
    "        # if the model decides to call function(s), call handle_tool_calls\n",
    "        if tool_calls:\n",
    "            print(\"Processing tool calls\")\n",
    "            messages = handle_tool_calls(tool_calls, messages)\n",
    "        else:\n",
    "            print(\"No tool calls, returning final response\")\n",
    "            return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5bb8861-7304-4d4a-ac8b-6ca1d7193e59",
   "metadata": {
    "height": 45
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agent with messages: who are you?\n",
      "Making router call to OpenAI\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n"
     ]
    }
   ],
   "source": [
    "result = run_agent('who are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1a59674-5bb3-4983-95ca-809e26743e87",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm your helpful assistant, here to assist you with questions and insights related to your dataset. How can I help you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(result)\n",
    "# you can also print a formatted version of the result\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa963d4-77da-4f5b-b8bf-6cb305929e2b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> ðŸ“’ &nbsp; For more help, please see the <em>\"Appendix â€“ Tips, Help, and Download\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
